{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocess data to get training and testing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I,II,III,aVL,aVR,aVF,V1–V6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MJx9Nhz6wOEC"
      },
      "outputs": [],
      "source": [
        "# Import package\n",
        "import time\n",
        "import numpy as np\n",
        "import wfdb\n",
        "import ast\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pylab import mpl\n",
        "from scipy.fftpack import fft, ifft \n",
        "from scipy import signal\n",
        "# from biosppy.signals import ecg\n",
        "import neurokit2 as nk\n",
        "from sklearn import *\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Set the read file path\n",
        "path = '/global/D1/homes/jayao/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.2/ptbxl/'\n",
        "\n",
        "X = np.load(path + 'raw100_segmented.npy', allow_pickle=True)\n",
        "sampling_rate = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read the file and convert tags\n",
        "Y = pd.read_csv(path+'ptbxl_database.csv', index_col='ecg_id')\n",
        "Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(21801, 100, 12)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get diagnostic information in scp_statements.csv\n",
        "agg_df = pd.read_csv(path+'scp_statements.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "agg_df = agg_df[agg_df.diagnostic == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def diagnostic_class(scp):\n",
        "    res = set()\n",
        "    for k in scp.keys():\n",
        "        if k in agg_df.index:\n",
        "            res.add(agg_df.loc[k].diagnostic_class)\n",
        "    return list(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def aggregate_diagnostic(y_dic):\n",
        "    tmp = []\n",
        "    for key in y_dic.keys():\n",
        "        if key in agg_df.index:\n",
        "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
        "    return list(set(tmp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y['scp_classes'] = Y.scp_codes.apply(diagnostic_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NORM</th>\n",
              "      <th>MI</th>\n",
              "      <th>STTC</th>\n",
              "      <th>CD</th>\n",
              "      <th>HYP</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ecg_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21833</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21834</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21835</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21836</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21837</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21801 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        NORM  MI  STTC  CD  HYP\n",
              "ecg_id                         \n",
              "1          1   0     0   0    0\n",
              "2          1   0     0   0    0\n",
              "3          1   0     0   0    0\n",
              "4          1   0     0   0    0\n",
              "5          1   0     0   0    0\n",
              "...      ...  ..   ...  ..  ...\n",
              "21833      0   0     1   0    0\n",
              "21834      1   0     0   0    0\n",
              "21835      0   0     1   0    0\n",
              "21836      1   0     0   0    0\n",
              "21837      1   0     0   0    0\n",
              "\n",
              "[21801 rows x 5 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Z = pd.DataFrame(0, index=Y.index, columns=['NORM', 'MI', 'STTC', 'CD', 'HYP'], dtype='int')\n",
        "for i in Z.index:\n",
        "    for k in Y.loc[i].scp_classes:\n",
        "        Z.loc[i, k] = 1\n",
        "\n",
        "Z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NORM</th>\n",
              "      <th>MI</th>\n",
              "      <th>STTC</th>\n",
              "      <th>CD</th>\n",
              "      <th>HYP</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ecg_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        NORM  MI  STTC  CD  HYP\n",
              "ecg_id                         \n",
              "30         0   0     0   0    1\n",
              "45         0   0     0   1    1\n",
              "96         0   0     0   0    1\n",
              "106        0   1     0   0    1\n",
              "138        0   0     0   0    1\n",
              "146        0   1     1   0    1\n",
              "162        0   1     1   1    1\n",
              "173        0   0     1   0    1\n",
              "191        0   0     0   1    1\n",
              "199        0   1     0   0    1\n",
              "211        0   1     0   0    1\n",
              "222        0   0     0   1    1\n",
              "223        0   1     1   0    1\n",
              "271        0   1     1   0    1\n",
              "273        0   0     1   0    1\n",
              "274        0   1     1   0    1\n",
              "282        0   1     1   1    1\n",
              "284        0   0     1   0    1\n",
              "296        0   0     1   0    1\n",
              "298        0   1     1   0    1"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hyp_cases = Z[Z['HYP'] == 1]\n",
        "hyp_cases.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Add diagnostic information\n",
        "Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_diagnostic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "diagnostic_superclass\n",
              "[NORM]                 9072\n",
              "[MI]                   2532\n",
              "[STTC]                 2401\n",
              "[CD]                   1708\n",
              "[CD, MI]               1300\n",
              "[HYP, STTC]             781\n",
              "[STTC, MI]              600\n",
              "[HYP]                   535\n",
              "[STTC, CD]              471\n",
              "[CD, NORM]              407\n",
              "[]                      405\n",
              "[HYP, STTC, MI]         361\n",
              "[HYP, CD]               300\n",
              "[STTC, CD, MI]          223\n",
              "[HYP, STTC, CD]         211\n",
              "[HYP, MI]               183\n",
              "[HYP, STTC, CD, MI]     156\n",
              "[HYP, CD, MI]           117\n",
              "[STTC, NORM]             28\n",
              "[STTC, CD, NORM]          5\n",
              "[HYP, CD, NORM]           2\n",
              "[HYP, NORM]               2\n",
              "[HYP, CD, NORM, MI]       1\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y.diagnostic_superclass.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(21801, 100, 12)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "X_all = X[(Y.strat_fold <= 11)]\n",
        "X_all.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "save_path = '/global/D1/homes/jayao/XAI-Based-ECG-Diagnostics-main/data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(17420, 100, 12) (17420,)\n",
            "(4381, 100, 12) (4381,)\n"
          ]
        }
      ],
      "source": [
        "# Split data into train and test\n",
        "test_fold = 10\n",
        "# # Train\n",
        "X_train = X[(Y.strat_fold <= 8)]\n",
        "# y_train = Z[Y.strat_fold <= 8]\n",
        "y_train = Y[(Y.strat_fold <= 8)].diagnostic_superclass\n",
        "# # Test\n",
        "X_test = X[(Y.strat_fold >8)]\n",
        "# y_test = Z[Y.strat_fold > 8]\n",
        "y_test = Y[(Y.strat_fold > 8)].diagnostic_superclass\n",
        "\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape,  y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ecg_id\n",
            "2691             [STTC]\n",
            "2695             [NORM]\n",
            "2696    [HYP, STTC, MI]\n",
            "2699             [NORM]\n",
            "2700             [NORM]\n",
            "             ...       \n",
            "4035             [NORM]\n",
            "4036             [NORM]\n",
            "4037             [NORM]\n",
            "4038           [CD, MI]\n",
            "4039             [NORM]\n",
            "Name: diagnostic_superclass, Length: 1000, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Display y_train for rows 100 to 150\n",
        "print(y_train.iloc[2000:3000])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "save_path = '/global/D1/homes/jayao/XAI-Based-ECG-Diagnostics-main/data/segmented/'\n",
        "\n",
        "np.save(save_path+'x_train.npy', X_train)\n",
        "np.save(save_path+'y_train.npy', np.array(y_train))\n",
        "np.save(save_path+'x_test.npy', X_test)\n",
        "np.save(save_path+'y_test.npy', np.array(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ECG SHaP starts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-05 13:24:53.691586: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-05 13:24:53.691644: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-05 13:24:53.692851: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-05 13:24:54.080404: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-05-05 13:25:09.681690: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers, optimizers, losses, metrics, activations, regularizers, callbacks\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJxT5hv-wjBM",
        "metadata": {},
        "outputId": "dd2d52f3-a3c2-4c46-9eea-9ec6046ac22f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(17420, 100, 12)\n"
          ]
        }
      ],
      "source": [
        "path = \"/global/D1/homes/jayao/XAI-Based-ECG-Diagnostics-main/data/segmented/\"\n",
        "x_train = np.load(path + 'x_train.npy')\n",
        "y_train = np.load(path + 'y_train.npy', allow_pickle=True)\n",
        "x_test  = np.load(path + 'x_test.npy')\n",
        "y_test  = np.load(path + 'y_test.npy', allow_pickle=True)\n",
        "print(x_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(17420, 12, 100)\n"
          ]
        }
      ],
      "source": [
        "x_train = x_train.transpose(0, 2, 1)            # transpose working correctly\n",
        "x_test  = x_test.transpose(0, 2, 1)\n",
        "print(x_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape(17420, 12, 100, 1)   # Add another channel\n",
        "x_test  = x_test.reshape(4381, 12, 100, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train : (17420, 12, 100, 1)\n",
            "y_train : (17420,)\n",
            "x_test  : (4381, 12, 100, 1)\n",
            "y_test  : (4381,)\n",
            "Data loaded\n"
          ]
        }
      ],
      "source": [
        "print(\"x_train :\", x_train.shape)\n",
        "print(\"y_train :\", y_train.shape)\n",
        "print(\"x_test  :\", x_test.shape)\n",
        "print(\"y_test  :\", y_test.shape)\n",
        "print('Data loaded')\n",
        "\n",
        "# Old OUTPUTS:\n",
        "# (19601, 1000, 12)\n",
        "# (19601, 12, 1000)\n",
        "# x_train : (19601, 12, 1000, 1)\n",
        "# y_train : (19601,)\n",
        "# x_test  : (2198, 12, 1000, 1)\n",
        "# y_test  : (2198,)\n",
        "# Data loaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxCCW4SO0fuX",
        "outputId": "3ad1f11c-835e-499b-ae90-d6b9c9a8c9f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4381, 12, 1000, 1)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffvWI7S-KWPh",
        "metadata": {},
        "outputId": "6e1db6ca-be32-4992-e7f0-3c1a674e878b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes: ['CD' 'HYP' 'MI' 'NORM' 'STTC']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "# Convert multi-label target labels to one-hot encoded matrix\n",
        "mlb = MultiLabelBinarizer()\n",
        "y_train = mlb.fit_transform(y_train)\n",
        "y_test = mlb.transform(y_test)\n",
        "print(\"Classes:\", mlb.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 1 0]\n"
          ]
        }
      ],
      "source": [
        "value_at_index = y_train[6666]\n",
        "print(value_at_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(17420, 5)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4381, 5)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk3y3dB3x65D",
        "metadata": {},
        "outputId": "476fc2a0-a68b-4785-c210-f6ac3706e5bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added 5 layers for temporal analysis\n",
            "Added 1 layer for spatial Analysis\n",
            "(None, 64)\n",
            "Added 2 fully connected layers\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 12, 100, 1)]         0         []                            \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 12, 96, 32)           192       ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 12, 96, 32)           128       ['conv2d_10[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_10 (ReLU)             (None, 12, 96, 32)           0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPoolin  (None, 12, 95, 32)           0         ['re_lu_10[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 12, 91, 32)           5152      ['max_pooling2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 12, 91, 32)           128       ['conv2d_12[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_11 (ReLU)             (None, 12, 91, 32)           0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPoolin  (None, 12, 88, 32)           0         ['re_lu_11[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 12, 89, 64)           14400     ['max_pooling2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 12, 84, 64)           10304     ['max_pooling2d_6[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 12, 84, 64)           24640     ['conv2d_11[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 12, 84, 64)           256       ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 12, 84, 64)           0         ['conv2d_13[0][0]',           \n",
            "                                                                     'batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_12 (ReLU)             (None, 12, 84, 64)           0         ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPoolin  (None, 12, 83, 64)           0         ['re_lu_12[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 12, 81, 64)           12352     ['max_pooling2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 12, 81, 64)           256       ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_13 (ReLU)             (None, 12, 81, 64)           0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPoolin  (None, 12, 78, 64)           0         ['re_lu_13[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 12, 80, 32)           8224      ['max_pooling2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 12, 76, 64)           12352     ['max_pooling2d_8[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 12, 76, 64)           10304     ['conv2d_15[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 12, 76, 64)           256       ['conv2d_18[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 12, 76, 64)           0         ['conv2d_17[0][0]',           \n",
            "                                                                     'batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_14 (ReLU)             (None, 12, 76, 64)           0         ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPoolin  (None, 12, 75, 64)           0         ['re_lu_14[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 1, 75, 64)            49216     ['max_pooling2d_9[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 1, 75, 64)            256       ['conv2d_19[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_15 (ReLU)             (None, 1, 75, 64)            0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 64)                   0         ['re_lu_15[0][0]']            \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)         (None, 64)                   0         ['global_average_pooling2d_1[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 128)                  8320      ['flatten_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 128)                  512       ['dense_3[0][0]']             \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_16 (ReLU)             (None, 128)                  0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 128)                  0         ['re_lu_16[0][0]']            \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 64)                   8256      ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 64)                   256       ['dense_4[0][0]']             \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_17 (ReLU)             (None, 64)                   0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 64)                   0         ['re_lu_17[0][0]']            \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 5)                    325       ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 166085 (648.77 KB)\n",
            "Trainable params: 165061 (644.77 KB)\n",
            "Non-trainable params: 1024 (4.00 KB)\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# ST-CNN\n",
        "# Main Version\n",
        "input = layers.Input(shape=(12, 100, 1))\n",
        "\n",
        "X = layers.Conv2D(filters=32, kernel_size=(1, 5))(input)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.ReLU()(X)\n",
        "X = layers.MaxPooling2D(pool_size=(1, 2), strides=1)(X)\n",
        "\n",
        "convC1 = layers.Conv2D(filters=64, kernel_size=(1, 7))(X)\n",
        "\n",
        "X = layers.Conv2D(filters=32, kernel_size=(1, 5))(X)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.ReLU()(X)\n",
        "X = layers.MaxPooling2D(pool_size=(1, 4), strides=1)(X)\n",
        "\n",
        "convC2 = layers.Conv2D(filters=64, kernel_size=(1, 6))(convC1)\n",
        "\n",
        "X = layers.Conv2D(filters=64, kernel_size=(1, 5))(X)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Add()([convC2, X])           # skip Connection\n",
        "X = layers.ReLU()(X)\n",
        "X = layers.MaxPooling2D(pool_size=(1, 2), strides=1)(X)\n",
        "\n",
        "convE1 = layers.Conv2D(filters=32, kernel_size=(1, 4))(X)\n",
        "\n",
        "X = layers.Conv2D(filters=64, kernel_size=(1, 3))(X)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.ReLU()(X)\n",
        "X = layers.MaxPooling2D(pool_size=(1, 4), strides=1)(X)\n",
        "\n",
        "convE2 = layers.Conv2D(filters=64, kernel_size=(1, 5))(convE1)\n",
        "\n",
        "X = layers.Conv2D(filters=64, kernel_size=(1, 3))(X)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Add()([convE2, X])         # skip Connection\n",
        "X = layers.ReLU()(X)\n",
        "X = layers.MaxPooling2D(pool_size=(1, 2), strides=1)(X)\n",
        "print('Added 5 layers for temporal analysis')\n",
        "\n",
        "X = layers.Conv2D(filters=64, kernel_size=(12, 1))(X)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.ReLU()(X)\n",
        "X = layers.GlobalAveragePooling2D()(X)\n",
        "print('Added 1 layer for spatial Analysis')\n",
        "\n",
        "X = layers.Flatten()(X)\n",
        "print(X.shape)\n",
        "\n",
        "X = layers.Dense(units=128, kernel_regularizer=regularizers.L2(0.005))(X)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.ReLU()(X)\n",
        "X = layers.Dropout(rate=0.1)(X)\n",
        "\n",
        "X = layers.Dense(units=64, kernel_regularizer=regularizers.L2(0.009))(X)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.ReLU()(X)\n",
        "X = layers.Dropout(rate=0.15)(X)\n",
        "print('Added 2 fully connected layers')\n",
        "\n",
        "output = layers.Dense(5, activation='sigmoid')(X)\n",
        "model = Model(inputs=input, outputs=output)\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hyper parameter tuning:\n",
        "EarlyStopping monitors a specified metric, here: \"val_loss\"\n",
        "If the val_loss does not improve for a certain number of epochs defined by patience (in this case, 6 epochs), training is stopped early.\n",
        "The restore_best_weights=True argument ensures that the weights of the model are restored to the best weights when training stopped.\n",
        "\n",
        "Learning Rate Reduction:\n",
        "ReduceLROnPlateau monitors the validation loss (\"val_loss\").\n",
        "If the validation loss does not improve for a certain number of epochs defined by patience (in this case, 3 epochs), the learning rate is reduced by a factor defined by factor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-05 13:26:17.716510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1562 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added 5 layers for temporal analysis\n",
            "Added 1 layer for spatial Analysis\n",
            "Added 2 fully connected layers\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 12, 100, 1)]         0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 12, 100, 32)          192       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 12, 100, 32)          128       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                (None, 12, 100, 32)          0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 12, 100, 32)          0         ['re_lu[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 12, 100, 32)          5152      ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 12, 100, 32)          128       ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)              (None, 12, 100, 32)          0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 12, 100, 32)          0         ['re_lu_1[0][0]']             \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 12, 100, 64)          10304     ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 12, 100, 64)          14400     ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 12, 100, 64)          256       ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 12, 100, 64)          24640     ['conv2d_1[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)              (None, 12, 100, 64)          0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 12, 100, 64)          0         ['conv2d_3[0][0]',            \n",
            "                                                                     're_lu_2[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)              (None, 12, 100, 64)          0         ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 12, 100, 64)          0         ['re_lu_3[0][0]']             \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 12, 100, 64)          12352     ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 12, 100, 64)          256       ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)              (None, 12, 100, 64)          0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 12, 100, 64)          0         ['re_lu_4[0][0]']             \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 12, 100, 64)          12352     ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 12, 100, 32)          8224      ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 12, 100, 64)          256       ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 12, 100, 64)          10304     ['conv2d_5[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_5 (ReLU)              (None, 12, 100, 64)          0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 12, 100, 64)          0         ['conv2d_7[0][0]',            \n",
            "                                                                     're_lu_5[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_6 (ReLU)              (None, 12, 100, 64)          0         ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPoolin  (None, 12, 100, 64)          0         ['re_lu_6[0][0]']             \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 12, 100, 64)          49216     ['max_pooling2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 12, 100, 64)          256       ['conv2d_9[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_7 (ReLU)              (None, 12, 100, 64)          0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 64)                   0         ['re_lu_7[0][0]']             \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 64)                   0         ['global_average_pooling2d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  8320      ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 128)                  512       ['dense[0][0]']               \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_8 (ReLU)              (None, 128)                  0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 128)                  0         ['re_lu_8[0][0]']             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 64)                   8256      ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 64)                   256       ['dense_1[0][0]']             \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_9 (ReLU)              (None, 64)                   0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 64)                   0         ['re_lu_9[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 5)                    325       ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 166085 (648.77 KB)\n",
            "Trainable params: 165061 (644.77 KB)\n",
            "Non-trainable params: 1024 (4.00 KB)\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# #Enhanced ST-CNN\n",
        "# from tensorflow.keras import layers, regularizers\n",
        "# from tensorflow.keras.models import Model\n",
        "\n",
        "# # Main Version\n",
        "# input = layers.Input(shape=(12, 100, 1))\n",
        "\n",
        "# X = layers.Conv2D(filters=32, kernel_size=(1, 5), padding='same')(input)\n",
        "# X = layers.BatchNormalization()(X)\n",
        "# X = layers.ReLU()(X)\n",
        "# X = layers.MaxPooling2D(pool_size=(1, 2), strides=1, padding='same')(X)\n",
        "\n",
        "# convC1 = layers.Conv2D(filters=64, kernel_size=(1, 7), padding='same')(X)\n",
        "\n",
        "# X = layers.Conv2D(filters=32, kernel_size=(1, 5), padding='same')(X)\n",
        "# X = layers.BatchNormalization()(X)\n",
        "# X = layers.ReLU()(X)\n",
        "# X = layers.MaxPooling2D(pool_size=(1, 4), strides=1, padding='same')(X)\n",
        "\n",
        "# convC2 = layers.Conv2D(filters=64, kernel_size=(1, 6), padding='same')(convC1)\n",
        "\n",
        "# X = layers.Conv2D(filters=64, kernel_size=(1, 5), padding='same')(X)\n",
        "# X = layers.BatchNormalization()(X)\n",
        "# X = layers.ReLU()(X)\n",
        "# residual_1 = layers.Add()([convC2, X])           # skip Connection\n",
        "# X = layers.ReLU()(residual_1)\n",
        "# X = layers.MaxPooling2D(pool_size=(1, 2), strides=1, padding='same')(X)\n",
        "\n",
        "# convE1 = layers.Conv2D(filters=32, kernel_size=(1, 4), padding='same')(X)\n",
        "\n",
        "# X = layers.Conv2D(filters=64, kernel_size=(1, 3), padding='same')(X)\n",
        "# X = layers.BatchNormalization()(X)\n",
        "# X = layers.ReLU()(X)\n",
        "# X = layers.MaxPooling2D(pool_size=(1, 4), strides=1, padding='same')(X)\n",
        "\n",
        "# convE2 = layers.Conv2D(filters=64, kernel_size=(1, 5), padding='same')(convE1)\n",
        "\n",
        "# X = layers.Conv2D(filters=64, kernel_size=(1, 3), padding='same')(X)\n",
        "# X = layers.BatchNormalization()(X)\n",
        "# X = layers.ReLU()(X)\n",
        "# residual_2 = layers.Add()([convE2, X])         # skip Connection\n",
        "# X = layers.ReLU()(residual_2)\n",
        "# X = layers.MaxPooling2D(pool_size=(1, 2), strides=1, padding='same')(X)\n",
        "# print('Added 5 layers for temporal analysis')\n",
        "\n",
        "# # Spatial Analysis\n",
        "# X = layers.Conv2D(filters=64, kernel_size=(12, 1), padding='same')(X)\n",
        "# X = layers.BatchNormalization()(X)\n",
        "# X = layers.ReLU()(X)\n",
        "# X = layers.GlobalAveragePooling2D()(X)\n",
        "# print('Added 1 layer for spatial Analysis')\n",
        "\n",
        "# # Fully Connected Layers\n",
        "# X = layers.Flatten()(X)\n",
        "# X = layers.Dense(units=128, kernel_regularizer=regularizers.L2(0.005))(X)\n",
        "# X = layers.BatchNormalization()(X)\n",
        "# X = layers.ReLU()(X)\n",
        "# X = layers.Dropout(rate=0.3)(X)\n",
        "\n",
        "# X = layers.Dense(units=64, kernel_regularizer=regularizers.L2(0.009))(X)\n",
        "# X = layers.BatchNormalization()(X)\n",
        "# X = layers.ReLU()(X)\n",
        "# X = layers.Dropout(rate=0.3)(X)\n",
        "# print('Added 2 fully connected layers')\n",
        "\n",
        "# # Output Layer\n",
        "# output = layers.Dense(5, activation='sigmoid')(X)\n",
        "\n",
        "# # Define the model\n",
        "# model = Model(inputs=input, outputs=output)\n",
        "# print(model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts0oUWQe98rm",
        "metadata": {},
        "outputId": "d40dd14f-9d6d-4798-99d4-1344474b4485"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "240/240 [==============================] - 24s 44ms/step - loss: 0.5583 - binary_accuracy: 0.8135 - auc_1: 0.8149 - val_loss: 0.5961 - val_binary_accuracy: 0.7455 - val_auc_1: 0.6065 - lr: 0.0050\n",
            "Epoch 2/20\n",
            "240/240 [==============================] - 8s 33ms/step - loss: 0.3973 - binary_accuracy: 0.8470 - auc_1: 0.8616 - val_loss: 0.4752 - val_binary_accuracy: 0.8097 - val_auc_1: 0.8545 - lr: 0.0050\n",
            "Epoch 3/20\n",
            "240/240 [==============================] - 8s 34ms/step - loss: 0.3744 - binary_accuracy: 0.8569 - auc_1: 0.8782 - val_loss: 0.5558 - val_binary_accuracy: 0.7374 - val_auc_1: 0.8411 - lr: 0.0050\n",
            "Epoch 4/20\n",
            "240/240 [==============================] - 8s 34ms/step - loss: 0.3573 - binary_accuracy: 0.8648 - auc_1: 0.8885 - val_loss: 0.4678 - val_binary_accuracy: 0.8043 - val_auc_1: 0.8569 - lr: 0.0050\n",
            "Epoch 5/20\n",
            "240/240 [==============================] - 8s 34ms/step - loss: 0.3479 - binary_accuracy: 0.8677 - auc_1: 0.8944 - val_loss: 0.5665 - val_binary_accuracy: 0.7649 - val_auc_1: 0.8624 - lr: 0.0050\n",
            "Epoch 6/20\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.3421 - binary_accuracy: 0.8690 - auc_1: 0.8961 - val_loss: 0.5088 - val_binary_accuracy: 0.7824 - val_auc_1: 0.8860 - lr: 0.0050\n",
            "Epoch 7/20\n",
            "240/240 [==============================] - 10s 40ms/step - loss: 0.3360 - binary_accuracy: 0.8725 - auc_1: 0.8997 - val_loss: 0.5594 - val_binary_accuracy: 0.7677 - val_auc_1: 0.8668 - lr: 0.0050\n",
            "Epoch 8/20\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.3035 - binary_accuracy: 0.8827 - auc_1: 0.9162 - val_loss: 0.3200 - val_binary_accuracy: 0.8739 - val_auc_1: 0.9205 - lr: 5.0000e-04\n",
            "Epoch 9/20\n",
            "240/240 [==============================] - 9s 38ms/step - loss: 0.2859 - binary_accuracy: 0.8873 - auc_1: 0.9218 - val_loss: 0.3058 - val_binary_accuracy: 0.8769 - val_auc_1: 0.9240 - lr: 5.0000e-04\n",
            "Epoch 10/20\n",
            "240/240 [==============================] - 9s 36ms/step - loss: 0.2797 - binary_accuracy: 0.8886 - auc_1: 0.9248 - val_loss: 0.2984 - val_binary_accuracy: 0.8796 - val_auc_1: 0.9230 - lr: 5.0000e-04\n",
            "Epoch 11/20\n",
            "240/240 [==============================] - 9s 37ms/step - loss: 0.2761 - binary_accuracy: 0.8891 - auc_1: 0.9263 - val_loss: 0.3264 - val_binary_accuracy: 0.8700 - val_auc_1: 0.9226 - lr: 5.0000e-04\n",
            "Epoch 12/20\n",
            "240/240 [==============================] - 9s 35ms/step - loss: 0.2745 - binary_accuracy: 0.8900 - auc_1: 0.9273 - val_loss: 0.2910 - val_binary_accuracy: 0.8777 - val_auc_1: 0.9253 - lr: 5.0000e-04\n",
            "Epoch 13/20\n",
            "240/240 [==============================] - 9s 36ms/step - loss: 0.2721 - binary_accuracy: 0.8908 - auc_1: 0.9292 - val_loss: 0.2967 - val_binary_accuracy: 0.8775 - val_auc_1: 0.9263 - lr: 5.0000e-04\n",
            "Epoch 14/20\n",
            "240/240 [==============================] - 8s 34ms/step - loss: 0.2694 - binary_accuracy: 0.8912 - auc_1: 0.9304 - val_loss: 0.3140 - val_binary_accuracy: 0.8719 - val_auc_1: 0.9213 - lr: 5.0000e-04\n",
            "Epoch 15/20\n",
            "240/240 [==============================] - 8s 32ms/step - loss: 0.2674 - binary_accuracy: 0.8941 - auc_1: 0.9314 - val_loss: 0.3318 - val_binary_accuracy: 0.8690 - val_auc_1: 0.9222 - lr: 5.0000e-04\n",
            "Epoch 16/20\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.2596 - binary_accuracy: 0.8959 - auc_1: 0.9355 - val_loss: 0.2820 - val_binary_accuracy: 0.8849 - val_auc_1: 0.9295 - lr: 5.0000e-05\n",
            "Epoch 17/20\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.2570 - binary_accuracy: 0.8973 - auc_1: 0.9370 - val_loss: 0.2801 - val_binary_accuracy: 0.8861 - val_auc_1: 0.9302 - lr: 5.0000e-05\n",
            "Epoch 18/20\n",
            "240/240 [==============================] - 8s 33ms/step - loss: 0.2568 - binary_accuracy: 0.8971 - auc_1: 0.9370 - val_loss: 0.2794 - val_binary_accuracy: 0.8862 - val_auc_1: 0.9304 - lr: 5.0000e-05\n",
            "Epoch 19/20\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.2546 - binary_accuracy: 0.8974 - auc_1: 0.9383 - val_loss: 0.2784 - val_binary_accuracy: 0.8859 - val_auc_1: 0.9308 - lr: 5.0000e-05\n",
            "Epoch 20/20\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.2529 - binary_accuracy: 0.8989 - auc_1: 0.9390 - val_loss: 0.2792 - val_binary_accuracy: 0.8857 - val_auc_1: 0.9306 - lr: 5.0000e-05\n"
          ]
        }
      ],
      "source": [
        "# Source: https://keras.io/api/callbacks/\n",
        "# Source: https://towardsdatascience.com/checkpointing-deep-learning-models-in-keras-a652570b8de6\n",
        "\n",
        "early    = callbacks.EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True)\n",
        "reducelr = callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=3)\n",
        "callback = [early, reducelr]\n",
        "\n",
        "# ST-CNN\n",
        "model.compile(optimizer = optimizers.Adam(learning_rate=0.005),\n",
        "# #Enhanced ST-CNN\n",
        "# model.compile(optimizer = optimizers.Adam(learning_rate=0.001),\n",
        "              loss = losses.BinaryCrossentropy(),\n",
        "              metrics = [metrics.BinaryAccuracy(), metrics.AUC(curve='ROC', multi_label=True)])\n",
        "\n",
        "history = model.fit(x_train, y_train, validation_split=0.12, epochs=20, batch_size=64, callbacks=callback)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V65iMb0hGJNE"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "LKWbmNBuGJkX",
        "metadata": {}
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/global/D1/homes/jayao/.venv/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "save_path = \"/global/D1/homes/jayao/XAI-Based-ECG-Diagnostics-main/model/\"\n",
        "# model.save(save_path + \"ST-CNN-5_final1.h5\")\n",
        "model.save(save_path + \"ST-CNN-5_final1_segmented.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model(r'/global/D1/homes/jayao/XAI-Based-ECG-Diagnostics-main/model/ST-CNN-5_final1_segmented.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "545/545 [==============================] - 4s 6ms/step\n",
            "137/137 [==============================] - 1s 8ms/step\n",
            "Accuracy        : 88.08\n",
            "Macro AUC score : 91.87\n",
            "AUROC           : 79.57\n",
            "Micro F1 score  : 75.48\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CD       0.79      0.68      0.73       992\n",
            "         HYP       0.75      0.38      0.51       530\n",
            "          MI       0.81      0.59      0.68      1092\n",
            "        NORM       0.80      0.92      0.86      1919\n",
            "        STTC       0.79      0.69      0.74      1049\n",
            "\n",
            "   micro avg       0.79      0.72      0.75      5582\n",
            "   macro avg       0.79      0.65      0.70      5582\n",
            "weighted avg       0.79      0.72      0.74      5582\n",
            " samples avg       0.77      0.74      0.74      5582\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/global/D1/homes/jayao/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/global/D1/homes/jayao/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "#ST-CNN\n",
        "y_pred_train = model.predict(x_train)\n",
        "y_pred_test  = model.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, precision_recall_curve, f1_score, roc_auc_score, accuracy_score, auc\n",
        "import numpy as np\n",
        "\n",
        "def sklearn_metrics(y_true, y_pred, mlb):\n",
        "    y_bin = np.copy(y_pred)\n",
        "    y_bin[y_bin >= 0.5] = 1\n",
        "    y_bin[y_bin < 0.5]  = 0\n",
        "\n",
        "#     print(\"y_train shape:\", y_true.shape)\n",
        "# p   print(\"y_test shape :\", y_pred.shape)\n",
        "\n",
        "\n",
        "    # Compute area under precision-Recall curve\n",
        "    auc_sum = 0\n",
        "    for i in range(y_true.shape[1]):\n",
        "        precision, recall, thresholds = precision_recall_curve(y_true[:, i], y_pred[:, i])\n",
        "        auc_sum += auc(recall, precision)\n",
        "\n",
        "    print(\"Accuracy        : {:.2f}\".format(accuracy_score(y_true.flatten(), y_bin.flatten()) * 100))\n",
        "    print(\"Macro AUC score : {:.2f}\".format(roc_auc_score(y_true, y_pred, average='macro') * 100))\n",
        "    print('AUROC           : {:.2f}'.format((auc_sum / y_true.shape[1]) * 100))\n",
        "    print(\"Micro F1 score  : {:.2f}\".format(f1_score(y_true, y_bin, average='micro') * 100))\n",
        "\n",
        "    # Convert binary predictions back to class labels using MultiLabelBinarizer\n",
        "    predicted_classes = mlb.inverse_transform(y_bin)\n",
        "\n",
        "    # Use a set to accumulate all distinct classes\n",
        "    distinct_classes = set()\n",
        "\n",
        "    # Iterate over predicted classes and add them to the set\n",
        "    for classes in predicted_classes:\n",
        "        distinct_classes.update(classes)\n",
        "\n",
        "    # Convert the set of distinct classes to a sorted list\n",
        "    class_names = sorted(list(distinct_classes))\n",
        "\n",
        "    # Print classification report for each class\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_bin, target_names=class_names))\n",
        "\n",
        "# Assuming mlb is the MultiLabelBinarizer used for transforming the labels\n",
        "sklearn_metrics(y_test, y_pred_test, mlb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "545/545 [==============================] - 5s 8ms/step\n",
            "137/137 [==============================] - 1s 8ms/step\n",
            "Accuracy        : 88.15\n",
            "Macro AUC score : 92.07\n",
            "AUROC           : 80.03\n",
            "Micro F1 score  : 75.73\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CD       0.78      0.70      0.74       992\n",
            "         HYP       0.67      0.50      0.57       530\n",
            "          MI       0.83      0.57      0.68      1092\n",
            "        NORM       0.84      0.86      0.85      1919\n",
            "        STTC       0.73      0.78      0.75      1049\n",
            "\n",
            "   micro avg       0.79      0.73      0.76      5582\n",
            "   macro avg       0.77      0.68      0.72      5582\n",
            "weighted avg       0.79      0.73      0.75      5582\n",
            " samples avg       0.76      0.74      0.74      5582\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/global/D1/homes/jayao/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/global/D1/homes/jayao/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# #Enhanced ST-CNN\n",
        "# y_pred_train = model.predict(x_train)\n",
        "# y_pred_test  = model.predict(x_test)\n",
        "\n",
        "# from sklearn.metrics import classification_report, precision_recall_curve, f1_score, roc_auc_score, accuracy_score, auc\n",
        "# import numpy as np\n",
        "\n",
        "# def sklearn_metrics(y_true, y_pred, mlb):\n",
        "#     y_bin = np.copy(y_pred)\n",
        "#     y_bin[y_bin >= 0.5] = 1\n",
        "#     y_bin[y_bin < 0.5]  = 0\n",
        "\n",
        "# #     print(\"y_train shape:\", y_true.shape)\n",
        "# # p   print(\"y_test shape :\", y_pred.shape)\n",
        "\n",
        "\n",
        "#     # Compute area under precision-Recall curve\n",
        "#     auc_sum = 0\n",
        "#     for i in range(y_true.shape[1]):\n",
        "#         precision, recall, thresholds = precision_recall_curve(y_true[:, i], y_pred[:, i])\n",
        "#         auc_sum += auc(recall, precision)\n",
        "\n",
        "#     print(\"Accuracy        : {:.2f}\".format(accuracy_score(y_true.flatten(), y_bin.flatten()) * 100))\n",
        "#     print(\"Macro AUC score : {:.2f}\".format(roc_auc_score(y_true, y_pred, average='macro') * 100))\n",
        "#     print('AUROC           : {:.2f}'.format((auc_sum / y_true.shape[1]) * 100))\n",
        "#     print(\"Micro F1 score  : {:.2f}\".format(f1_score(y_true, y_bin, average='micro') * 100))\n",
        "\n",
        "#     # Convert binary predictions back to class labels using MultiLabelBinarizer\n",
        "#     predicted_classes = mlb.inverse_transform(y_bin)\n",
        "\n",
        "#     # Use a set to accumulate all distinct classes\n",
        "#     distinct_classes = set()\n",
        "\n",
        "#     # Iterate over predicted classes and add them to the set\n",
        "#     for classes in predicted_classes:\n",
        "#         distinct_classes.update(classes)\n",
        "\n",
        "#     # Convert the set of distinct classes to a sorted list\n",
        "#     class_names = sorted(list(distinct_classes))\n",
        "\n",
        "#     # Print classification report for each class\n",
        "#     print(\"\\nClassification Report:\")\n",
        "#     print(classification_report(y_true, y_bin, target_names=class_names))\n",
        "\n",
        "# # Assuming mlb is the MultiLabelBinarizer used for transforming the labels\n",
        "# sklearn_metrics(y_test, y_pred_test, mlb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
